{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5x21QrSszl9L",
        "outputId": "39eb351b-be1c-4979-e631-29a2fef03a0b"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "from captum.attr import Saliency\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. データセットの準備\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "# MNISTデータセットをダウンロード\n",
        "full_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "# 数字'7'を正常、その他を異常とする\n",
        "normal_class = 7\n",
        "normal_indices = [i for i, (img, label) in enumerate(full_dataset) if label == normal_class]\n",
        "abnormal_indices = [i for i, (img, label) in enumerate(full_dataset) if label != normal_class]\n",
        "\n",
        "# 正常データのみで学習データローダーを作成\n",
        "train_dataset = Subset(full_dataset, normal_indices)\n",
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "\n",
        "# テスト用に正常・異常データを少量用意\n",
        "test_normal_dataset = Subset(full_dataset, normal_indices[:100])\n",
        "test_abnormal_dataset = Subset(full_dataset, abnormal_indices[:100])\n",
        "test_loader = DataLoader(torch.utils.data.ConcatDataset([test_normal_dataset, test_abnormal_dataset]), batch_size=1, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2. モデルの構築 (CNNオートエンコーダ)\n",
        "class ConvAutoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvAutoencoder, self).__init__()\n",
        "        # エンコーダ\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, 3, stride=2, padding=1), # -> 16x14x14\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(16, 32, 3, stride=2, padding=1), # -> 32x7x7\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, 7) # -> 64x1x1 (これが潜在空間)\n",
        "        )\n",
        "        # デコーダ\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose2d(64, 32, 7), # -> 32x7x7\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(32, 16, 3, stride=2, padding=1, output_padding=1), # -> 16x14x14\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(16, 1, 3, stride=2, padding=1, output_padding=1), # -> 1x28x28\n",
        "            nn.Tanh() # 出力範囲を-1~1に\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        latent = self.encoder(x)\n",
        "        reconstructed = self.decoder(latent)\n",
        "        return reconstructed, latent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3. 学習\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = ConvAutoencoder().to(device)\n",
        "criterion = nn.MSELoss() # 再構成誤差としてMean Squared Errorを使用\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    for data in train_loader:\n",
        "        img, _ = data\n",
        "        img = img.to(device)\n",
        "\n",
        "        # 順伝播\n",
        "        recon, _ = model(img)\n",
        "        loss = criterion(recon, img)\n",
        "\n",
        "        # 逆伝播\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "print(\"学習完了！\")\n",
        "\n",
        "\n",
        "# 4. 可視化と解釈\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# A. 再構成誤差の比較\n",
        "print(\"\\n--- A. 再構成結果の比較 ---\")\n",
        "fig, axes = plt.subplots(4, 5, figsize=(10, 8))\n",
        "fig.suptitle(\"Top: Original, Bottom: Reconstructed (Left: Normal, Right: Abnormal)\")\n",
        "# 正常データ\n",
        "for i in range(5):\n",
        "    img, _ = test_normal_dataset[i]\n",
        "    img = img.unsqueeze(0).to(device)\n",
        "    recon, _ = model(img)\n",
        "\n",
        "    axes[0, i].imshow(img.cpu().squeeze().numpy(), cmap='gray')\n",
        "    axes[0, i].set_title(\"Normal (Orig)\")\n",
        "    axes[0, i].axis('off')\n",
        "    axes[1, i].imshow(recon.cpu().detach().squeeze().numpy(), cmap='gray')\n",
        "    axes[1, i].set_title(\"Normal (Recon)\")\n",
        "    axes[1, i].axis('off')\n",
        "\n",
        "# 異常データ\n",
        "for i in range(5):\n",
        "    img, _ = test_abnormal_dataset[i]\n",
        "    img = img.unsqueeze(0).to(device)\n",
        "    recon, _ = model(img)\n",
        "\n",
        "    axes[2, i].imshow(img.cpu().squeeze().numpy(), cmap='gray')\n",
        "    axes[2, i].set_title(\"Abnormal (Orig)\")\n",
        "    axes[2, i].axis('off')\n",
        "    axes[3, i].imshow(recon.cpu().detach().squeeze().numpy(), cmap='gray')\n",
        "    axes[3, i].set_title(\"Abnormal (Recon)\")\n",
        "    axes[3, i].axis('off')\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# B. 潜在空間の可視化 (t-SNE)\n",
        "print(\"\\n--- B. 潜在空間の可視化 ---\")\n",
        "latents = []\n",
        "labels = []\n",
        "with torch.no_grad():\n",
        "    for img, label in DataLoader(torch.utils.data.ConcatDataset([test_normal_dataset, test_abnormal_dataset]), batch_size=64):\n",
        "        img = img.to(device)\n",
        "        _, latent = model(img)\n",
        "        latents.append(latent.cpu().view(latent.size(0), -1))\n",
        "        # 正常(7)なら1, 異常なら0\n",
        "        labels.append((label == normal_class).long())\n",
        "\n",
        "latents = torch.cat(latents).numpy()\n",
        "labels = torch.cat(labels).numpy()\n",
        "\n",
        "tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
        "latents_2d = tsne.fit_transform(latents)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(latents_2d[labels==1, 0], latents_2d[labels==1, 1], c='blue', label='Normal (7)', alpha=0.7)\n",
        "plt.scatter(latents_2d[labels==0, 0], latents_2d[labels==0, 1], c='red', label='Abnormal', alpha=0.7)\n",
        "plt.title('t-SNE visualization of Latent Space')\n",
        "plt.xlabel('t-SNE dimension 1')\n",
        "plt.ylabel('t-SNE dimension 2')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# C. 判断根拠の可視化 (Saliency Map / Grad-CAMの簡易版)\n",
        "# CaptumのSaliencyを使って、再構成誤差に対する入力の勾配を計算\n",
        "# これにより、誤差に大きく貢献したピクセル（＝モデルがうまく再構成できなかった場所）がわかる\n",
        "print(\"\\n--- C. 判断根拠の可視化 ---\")\n",
        "def attribute_image_features(model, image, target_recon):\n",
        "    model.zero_grad()\n",
        "    # 損失（再構成誤差）を計算するダミーの関数\n",
        "    # Saliencyは「出力」に対する「入力」の勾配を計算するが、今回は「損失」に対する勾配を見たい\n",
        "    # そのため、モデルの出力とターゲットから損失を計算する処理をラップする\n",
        "    def loss_fn(recon):\n",
        "        return criterion(recon, target_recon)\n",
        "\n",
        "    # モデル出力をラップして、入力（画像）-> 損失 の流れを作る\n",
        "    def model_wrapper(image):\n",
        "      recon, _ = model(image)\n",
        "      return loss_fn(recon)\n",
        "\n",
        "    # Saliencyを計算\n",
        "    saliency = Saliency(model_wrapper)\n",
        "    grads = saliency.attribute(image, abs=True) # 勾配の絶対値を取る\n",
        "    return grads\n",
        "\n",
        "# 異常データで試す\n",
        "img, _ = test_abnormal_dataset[10] # 適当な異常データを選ぶ\n",
        "img = img.unsqueeze(0).to(device)\n",
        "recon, _ = model(img)\n",
        "\n",
        "# 顕著性マップを計算\n",
        "saliency_map = attribute_image_features(model, img, img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 可視化\n",
        "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
        "axes[0].imshow(img.cpu().squeeze().numpy(), cmap='gray')\n",
        "axes[0].set_title('Original Abnormal Image')\n",
        "axes[0].axis('off')\n",
        "\n",
        "axes[1].imshow(recon.cpu().detach().squeeze().numpy(), cmap='gray')\n",
        "axes[1].set_title('Reconstructed Image')\n",
        "axes[1].axis('off')\n",
        "\n",
        "im = axes[2].imshow(saliency_map.cpu().squeeze().numpy(), cmap='hot')\n",
        "axes[2].set_title('Saliency Map (Error Attribution)')\n",
        "axes[2].axis('off')\n",
        "fig.colorbar(im, ax=axes[2])\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "daiki",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
