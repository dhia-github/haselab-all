{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8e30a3a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\furaf\\Desktop\\haselab-all\\PyTorch_practice\\wandb\\run-20250517_212724-27tol5tj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/fukui-university/haselab-conpetition/runs/27tol5tj' target=\"_blank\">experiment-20250517-212724</a></strong> to <a href='https://wandb.ai/fukui-university/haselab-conpetition' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/fukui-university/haselab-conpetition' target=\"_blank\">https://wandb.ai/fukui-university/haselab-conpetition</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/fukui-university/haselab-conpetition/runs/27tol5tj' target=\"_blank\">https://wandb.ai/fukui-university/haselab-conpetition/runs/27tol5tj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/fukui-university/haselab-conpetition/runs/27tol5tj?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x29d0c7ffca0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "from datetime import datetime\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "wandb.init(project=\"haselab-conpetition\", name=f\"experiment-{timestamp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4043a303",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import subprocess\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "633ea1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセットをダウンロード・展開するコード\n",
    "# 学外にいる場合や，Google Colaboratory で実行する場合，このコードはうまく動かない．\n",
    "# データセットをアクセスできる場所に置き，dataset_dir にデータセットのパスを指定する必要がある．\n",
    "\n",
    "# 具体的手順は以下\n",
    "# Google Colaboratory で実行する場合\n",
    "# 1. Aの部分をコメントアウト\n",
    "# 2. zipファイルをアップロードする．\n",
    "# 3. Bの部分をアンコメント\n",
    "\n",
    "# それ以外\n",
    "# 1. competition_images/ をアクセスできる場所に置く\n",
    "# 2. Aの部分をコメントアウト\n",
    "# 3. Cをアンコメントし，competitions_images/ のパスとなる文字列を格納  Ex.) dataset_dir = \"/home/haselab/Documents/tat/tmp/competition_images\"\n",
    "\n",
    "\n",
    "\n",
    "#      ----- A -----\n",
    "#      # データセットの保存先を指定\n",
    "#      save_dir = str(Path().resolve()) # 保存ディレクトリをノートブックと同じディレクトリに設定\n",
    "#      dataset_dir = save_dir + \"/competition_images/\"\n",
    "#      # データセットを保存\n",
    "#      if Path(dataset_dir).exists():\n",
    "#          print(f\"Dataset directory already exists: {dataset_dir}\")\n",
    "#      else:\n",
    "#          zip_path = Path(str(save_dir)) / \"tmp.zip\"\n",
    "#          url = \"http://10.0.87.42:8080/dataset\" # こっちでもいける\n",
    "#          subprocess.run([\"wget\", url, \"-O\", zip_path, \"--no-proxy\", \"-q\"], check=True) # .pyならこっち\n",
    "#          # !wget -O {zip_path} {url} -q --no-proxy\n",
    "#          with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "#              zip_ref.extractall(save_dir)\n",
    "#              if zip_path.exists():\n",
    "#                  zip_path.unlink()\n",
    "#          print(f\"Downloaded to {save_dir} and extracted.\")\n",
    "#      ----- A -----\n",
    "\n",
    "\n",
    "\n",
    "# ----- B -----\n",
    "# zip_path = \"/content/competition_images.zip\" # zipファイルのパスを指定\n",
    "# ext_dir = \"/content/\"  # 展開先を指定\n",
    "\n",
    "# with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "#     zip_ref.extractall(ext_dir)\n",
    "# dataset_dir = ext_dir + \"competition_images/\" # データセットのパスを指定\n",
    "# ----- B -----\n",
    "\n",
    "\n",
    "# ----- C -----\n",
    "dataset_dir = \"./content/competition_images\" # 要変更．データセットのパスを指定\n",
    "# ----- C -----\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f3c8045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# テストデータ読み込みのためのカスタムデータセットクラス\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, path, transform=None, target_transform=None):\n",
    "        self.img_paths = sorted([p for p in Path(path).iterdir()])\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path = self.img_paths[index]\n",
    "        data = Image.open(path).convert('RGB')\n",
    "\n",
    "        if self.transform: # 画像の前処理\n",
    "            data = self.transform(data)\n",
    "        if self.target_transform:\n",
    "            path = self.target_transform(path) # 画像のパスに前処理している。名前を変更？\n",
    "        return data, str(path.name)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a507e01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ハイパーパラメータを指定\n",
    "epochs = 5\n",
    "lr = 0.001\n",
    "batch_size = 128\n",
    "\n",
    "wandb.config.update({\n",
    "    \"epochs\": epochs,\n",
    "    \"learning_rate\": lr,\n",
    "    \"batch_size\": batch_size\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "53edc45b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device : GPU\n"
     ]
    }
   ],
   "source": [
    "# モデルと訓練に必要なものを定義\n",
    "num_classes = 4\n",
    "\n",
    "train_tf = torchvision.transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.3, 0.3, 0.3], std=[0.3, 0.3, 0.3])\n",
    "])\n",
    "test_tf = torchvision.transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.3, 0.3, 0.3], std=[0.3, 0.3, 0.3])\n",
    "])\n",
    "\n",
    "train_ds = ImageFolder(root=dataset_dir + \"/train_val\", transform=train_tf)\n",
    "test_ds = TestDataset(path=dataset_dir + \"/test\", transform=test_tf)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "test_dl = DataLoader(test_ds, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "\n",
    "model = torchvision.models.resnet18(num_classes=num_classes) # 事前学習済みモデルを使用しない重みはランダム初期化\n",
    "\n",
    "# model = models.resnet18(pretrained=True) # 事前学習済みモデルを使用する。ファインチューニング\n",
    "#num_ftrs = model.fc.in_features # 元の全結合層の入力特徴数を入手\n",
    "#model.fc = nn.Linear(num_ftrs, 10) # 全結合層を新しく定義\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"using device : \" + ( \"GPU\" if device.type == \"cuda\" else \"CPU\" )) #どっちつかってるか確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb863d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練フローを定義\n",
    "def train_1epoch(model, train_dl, criterion, optimizer, scheduler=None, device=\"cpu\"):\n",
    "    total_loss = 0.0\n",
    "    total_corr = 0\n",
    "\n",
    "    model.train()                                       # 訓練モードに設定\n",
    "    for inputs, labels in train_dl:                     # ミニバッチを取得してループ\n",
    "        inputs = inputs.to(device)                      # GPU に転送\n",
    "        labels = labels.to(device)                      # GPU に転送\n",
    "\n",
    "        outputs = model(inputs)                         # 順伝播\n",
    "\n",
    "        loss = criterion(outputs, labels)               # 損失計算\n",
    "        preds = torch.argmax(outputs.detach(), dim=1)   # 予測値を取得 各データの予測の最大値のインデックスを収集する操作なので、別に追跡する必要はないってかしたら勾配計算が異常になるのでdetach()。\n",
    "        corr = torch.sum(preds == labels.data).item()   # 正解数をカウント\n",
    "\n",
    "        optimizer.zero_grad()                           # 勾配を初期化\n",
    "        loss.backward()                                 # 誤差逆伝播\n",
    "        optimizer.step()                                # 重み更新\n",
    "\n",
    "        total_loss += loss.item() * len(inputs)         # 損失を累積\n",
    "        total_corr += corr                              # 正解数を累積\n",
    "\n",
    "    if scheduler is not None:                           # 学習率スケジューラが指定されている場合\n",
    "        scheduler.step()                                # 学習率を更新\n",
    "    train_loss = total_loss / len(train_dl.dataset)     # 平均損失を計算\n",
    "    train_acc = total_corr / len(train_dl.dataset)      # 平均精度を計算\n",
    "\n",
    "    return train_loss, train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2e631371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 推論フローを定義\n",
    "def pred(model, test_dl, device, probs=False, categorize=False):\n",
    "    total_outputs = []\n",
    "    all_labels = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_dl:\n",
    "            inputs = inputs.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            if probs:\n",
    "                outputs = torch.softmax(outputs, dim=1)\n",
    "\n",
    "            if categorize:\n",
    "                outputs = torch.argmax(outputs, dim=1)\n",
    "\n",
    "            total_outputs.append(outputs)\n",
    "            all_labels.extend(labels)\n",
    "\n",
    "    outputs = torch.cat(total_outputs, dim=0).cpu().tolist()\n",
    "    return outputs, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9c69e37e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   1/  5: train_loss: 0.3398, train_acc: 0.8775\n",
      "epoch   2/  5: train_loss: 0.2880, train_acc: 0.8917\n",
      "epoch   3/  5: train_loss: 0.3109, train_acc: 0.8900\n",
      "epoch   4/  5: train_loss: 0.2646, train_acc: 0.9050\n",
      "epoch   5/  5: train_loss: 0.2555, train_acc: 0.9042\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>▁▅▄██</td></tr><tr><td>train_loss</td><td>█▄▆▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>0.90417</td></tr><tr><td>train_loss</td><td>0.25546</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">experiment-20250517-212724</strong> at: <a href='https://wandb.ai/fukui-university/haselab-conpetition/runs/27tol5tj' target=\"_blank\">https://wandb.ai/fukui-university/haselab-conpetition/runs/27tol5tj</a><br> View project at: <a href='https://wandb.ai/fukui-university/haselab-conpetition' target=\"_blank\">https://wandb.ai/fukui-university/haselab-conpetition</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250517_212724-27tol5tj\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 訓練\n",
    "model = model.to(device)\n",
    "for epoch in range(epochs):\n",
    "    train_loss, train_acc = train_1epoch(model, train_dl, criterion, optimizer, device=device)\n",
    "    print(f\"epoch {epoch+1:>3}/{epochs:>3}: train_loss: {train_loss:.4f}, train_acc: {train_acc:.4f}\")\n",
    "\n",
    "    wandb.log({\"train_accuracy\": train_acc, \"train_loss\": train_loss}) # wandb にログを記録\n",
    "\n",
    "wandb.save(f\"model_epoch{epoch+1}.pth\") # wandb にモデルを保存\n",
    "wandb.finish() # wandb のセッションを終了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa41216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 推論・結果をCSV形式で保存\n",
    "csv_name = \"predictions.csv\"\n",
    "\n",
    "outputs, all_labels = pred(model, test_dl, device, categorize=True)\n",
    "lines = [f\"{l},{o}\" for o, l in zip(outputs, all_labels)]\n",
    "csv_text = \"\\n\".join(lines)\n",
    "\n",
    "with open(csv_name, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(csv_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
